name: 'ai-chat-ollama-spring-boot'
services:
  chat-ai:
    container_name: chat_ai
    build:
      ./build
    image: yuknow/chat-ai:latest
    depends_on:
      - ollama
    ports:
      - 8080:8080
    environment:
      SPRING_AI_OLLAMA_BASEURL: http://ollama:11434/

  ollama:
    hostname: ollama
    container_name: ollama
    image: ollama/ollama
    healthcheck:
      test: ollama list || exit 1
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 10s
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
  ollama-models-pull:
    image: curlimages/curl:8.6.0
    command: >-
      http://ollama:11434/api/pull -d '{"name": "llama3.1"}'
    depends_on:
      ollama:
        condition: service_healthy

volumes:
  ollama_data: